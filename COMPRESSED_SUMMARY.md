# 压缩摘要

## 用户需求与目标
- 原始目标: 创建一个基于Excel的病种识别系统，支持自定义提示词调试。
- 当前目标: 优化系统以稳定处理20000条数据，将服务器超时时间延长至120分钟，提升并发处理能力以减少总耗时。

## 项目概览
- 概述: 基于Next.js的Excel病种识别系统，采用非流式LLM调用配合SSE实时进度推送。支持自动重试、断点续传、自定义提示词、详细的错误日志追踪及分批文件保存。
- 技术栈:
  - Next.js 16 (App Router)
  - React 19
  - TypeScript 5
  - shadcn/ui (UI组件)
  - Tailwind CSS 4
  - xlsx (Excel处理)
  - coze-coding-dev-sdk (LLM集成)
- 编码规范: 使用TypeScript标准规范。

## 关键决策
- **架构调整**：放弃SSE流式输出，改用非流式`client.invoke`调用，解决LLM调用卡住导致任务中断的问题。
- **并发处理**：实现批量并发处理机制，每批次处理20条数据，大幅提升处理效率。
- **分批保存策略**：每处理100条数据，自动保存为一个独立的CSV文件到`/tmp/excel-exports`目录，防止因中断导致大量数据丢失。
- **模型切换**：将模型从`doubao-seed-1-8-251228`切换为`deepseek-v3-2-251201`，以应对低成功率问题。
- **超时优化**：将单次LLM调用超时从60秒缩短至15秒，配合5次重试机制，快速失败并重试。
- **长时运行保障**：将服务器`maxDuration`从15分钟逐步延长至120分钟，以支持20000条数据的稳定运行。
- **心跳保活**：每5个批次（100条）发送一次SSE心跳事件，保持连接活跃，防止长时间运行导致连接断开。
- **性能优化**：
  - 减少日志IO操作（注释掉每条数据的DEBUG/INFO日志，只保留错误日志和重要进度日志）
  - 降低心跳发送频率（从每批次改为每5批次）
  - 减少进度更新频率（从每10条改为每100条）
- **内存优化**（关键修复）：
  - 临时文件不再保存完整results数组，只保存processedCount、savedFiles和统计计数器
  - 每100条清空results数组，避免内存无限增长
  - 使用独立计数器（successCount、failureCount、totalDiseases）替代results数组遍历统计

## 核心文件修改
- 文件操作:
  - edit: `src/app/api/analyze/route.ts` (优化并发、增加超时、添加心跳、性能优化、内存优化)
  - edit: `src/app/api/retry/route.ts` (修正LLM调用方法)
  - edit: `src/app/page.tsx` (添加超时检测、修复历史记录、优化下载提示)
- 关键修改:
  - 实现并发处理逻辑，将`CONCURRENT_BATCH_SIZE`提升至20。
  - 修正LLM调用方法，统一使用`client.invoke`。
  - 添加SSE心跳机制，每5个批次（100条）发送一次`heartbeat`事件。
  - 增加服务器超时时间至120分钟（`maxDuration = 7200`）。
  - 前端添加60秒无数据超时检测与警告。
  - 修复历史记录保存逻辑，延迟保存以确保状态已更新。
  - 优化分析完成提示，使用独立状态控制显示，防止闪烁。
  - 性能优化：注释掉每条数据的DEBUG和INFO日志；心跳发送频率从每批次改为每5批次；进度更新从每10条改为每100条。
  - 内存优化：
    - saveTempFile只保存processedCount、savedFiles和统计计数器，不保存完整results
    - 每100条保存后清空results数组（`results.length = 0`）
    - 添加successCount、failureCount、totalDiseases独立计数器
    - 断点续传时兼容新旧两种临时文件格式

## 问题或错误及解决方案
- 问题: LLM流式调用（`client.stream`）经常卡住，导致任务中断且无错误日志，重试机制失效。
  - 解决方案: 放弃流式调用，改用非流式`client.invoke`。虽然牺牲了实时性，但极大提高了稳定性。
- 问题: 处理大量数据时成功率低，中断后大量已处理数据丢失。
  - 解决方案: 实现分批保存机制，每100条保存一个独立文件，确保即使中断也能保留大部分成果。
- 问题: 代码中使用了不存在的`client.chat`方法，导致分析失败。
  - 解决方案: 将所有API中的LLM调用统一改为`client.invoke`。
- 问题: 后端创建了result数据但未通过SSE发送，导致前端结果为空，下载失败。
  - 解决方案: 在成功、失败及异常处理逻辑中，立即通过`controller.enqueue`发送数据给前端。
- 问题: 分析完成提示卡片一闪而过，用户无法点击下载。
  - 解决方案: 新增独立的`showCompletionBanner`状态控制提示显示，添加手动关闭按钮。
- 问题: 执行到1300条左右时出现中断，可能与长时间运行有关。
  - 解决方案: 增加服务器超时时间至120分钟，添加SSE心跳保活机制，前端增加超时检测。
- 问题: 处理20000条数据时，每条数据的日志记录和频繁的心跳/进度更新导致IO和网络开销过大。
  - 解决方案: 注释掉每条数据的DEBUG和INFO日志，只保留错误日志和重要进度日志；心跳发送频率从每批次改为每5批次（每100条）；进度更新从每10条改为每100条。
- 问题: **处理2600条数据时突然中断，内存和IO压力过大导致系统崩溃**。
  - 根本原因:
    1. results数组一直累积所有结果，处理2600条时占用大量内存
    2. saveTempFile每次保存完整results数组，导致：
       - JSON.stringify处理大量数据，CPU密集
       - 写入大文件，IO密集
       - 内存峰值（results数组 + JSON字符串 + 写入缓冲区）
  - 解决方案:
    1. saveTempFile只保存processedCount、savedFiles和统计计数器，不保存完整results
    2. 每100条保存后立即清空results数组（`results.length = 0`）
    3. 使用独立计数器（successCount、failureCount、totalDiseases）替代results数组遍历统计
    4. 断点续传时兼容新旧两种临时文件格式
- 问题: **优化后仍然在2600条左右中断，日志显示请求在112秒后返回200**。
  - 根本原因: 沙箱平台对单个SSE连接有隐藏的超时限制或资源限制，导致连接在约2分钟后被强制关闭。
  - 证据:
    1. 日志显示请求在112秒后返回200，但处理2600条数据需要更长时间
    2. 没有OOM、SIGKILL等明显错误
    3. 总是在相同位置（2600条左右）中断
    4. 无论代码中如何设置`maxDuration = 7200`，都无法突破平台限制
  - 解决方案: **部署到本地环境运行**，可以完全控制服务器配置和资源限制。
  - 本地部署文件:
    - `LOCAL_DEPLOYMENT.md` - 完整的本地部署指南
    - `start.sh` - Linux/macOS快速启动脚本
    - `start.bat` - Windows快速启动脚本
    - `README_LOCAL.md` - 本地部署快速入门

## 性能与内存优化效果预估

### 性能优化措施
1. **减少日志IO操作**：
   - 注释掉每条数据的DEBUG日志
   - 注释掉每条数据成功的INFO日志
   - 只保留重试时的INFO日志和错误日志
   - 只保留重要进度日志（如批量保存）
   
2. **减少网络IO操作**：
   - 心跳发送频率：从每批次（20条）改为每5批次（100条）
   - 进度更新频率：从每10条改为每100条
   - 每条数据的结果仍然实时发送

3. **内存优化措施**：
   - results数组每100条清空一次
   - 临时文件只保存进度和统计，不保存完整results
   - 独立计数器替代results数组遍历

### 预期效果
对于20000条数据：

| 指标 | 优化前 | 优化后 | 减少比例 |
|------|--------|--------|----------|
| 日志写入次数 | 约60000次 | 约200次 | 99.7% |
| 心跳发送次数 | 1000次 | 200次 | 80% |
| 进度更新次数 | 2000次 | 200次 | 90% |
| results数组内存峰值 | 20000条数据 | 100条数据 | 99.5% |
| 临时文件大小 | 约100MB | 约1KB | 99.99% |
| **预计总耗时** | **约4-5小时** | **约2-3小时** | **40-50%** |

## TODO
- 测试内存优化后的实际效果（处理20000条数据）
